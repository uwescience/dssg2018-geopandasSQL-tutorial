{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to manipulate data in Pandas, the next segment will cover how to interface with databases from your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get back to the data frames we had before\n",
    "import geopandas as gpd\n",
    "\n",
    "df = gpd.pd.read_csv('data/Places_Full.csv')\n",
    "dfD = gpd.pd.read_csv('data/Dist_Out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL Databases - What and why\n",
    "\n",
    "We've been using geopandas to manipulate the data and have started to do some interesting analysis. Now we want to store the results. What are our options?\n",
    "\n",
    "One of them is the to_csv method. This will let us export or data frame in the same format we were importing earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a database? \n",
    "\n",
    "* a database is a software system for _capturing_, _storing_ and _analyzing_ data. \n",
    "* nearly all databases use the _relational_ data model in which information is structured in row and column format: \n",
    "\n",
    "<img src=\"terminology.png\" width = \"600\">\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "## Motivation for using a database\n",
    "\n",
    "* fast searching\n",
    "* powerful methods for performing analysis on groups of data\n",
    "* capability of joining information between datasets\n",
    "* data types have unique functionality (e.g. dates are not just integers but have methods related to year, month, day)\n",
    "* centralized repository, minimizes duplication, controlled access across multiple users\n",
    "* optional: geospatial encoding  \n",
    "\n",
    "## The relational data model:\n",
    "\n",
    "* there are many different flavors of databases but the most well developed is the _relational_ data model\n",
    "   * each record has a unique identifier (primary key)\n",
    "   * data are manipulated using _Structured Query Language_ (SQL):   \n",
    "\n",
    "## Structured Query Language (SQL):\n",
    "* standard language for relational databases\n",
    "* across different databases the core syntax is similar but there are small differences in some function names\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### Data Types\n",
    "\n",
    "* all data in a column must be of the same data type\n",
    "* this is required by SQL so that the database knows how to operate on the data in a consistent way\n",
    "* here are a few common [data types](https://www.postgresql.org/docs/9.4/static/datatype.html):\n",
    "\n",
    "| Name | Aliases | Description |\n",
    "| --- | --- | --- |\n",
    "|  boolean | bool | logical Boolean (true/false) |\n",
    "| character | varchar(n) | fixed-length character string |\n",
    "| date |  | calendar date (year, month, day) |\n",
    "| double precision | float | double precision floating-point number |\n",
    "| integer | int| signed four-byte integer |\n",
    "| timestamp |  | date and time (no time zone) |\n",
    "| text | text | arbitrary length text |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talking to a database from Pandas/Geopandas\n",
    "\n",
    "The pandas library supports importing and exporting data from an outside database, using the SQL language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need the pandas library as Geopandas doesn't support all the \n",
    "# SQL functions that we might want.\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need some way to connect to our database. In this case we\n",
    "# are using SQLite to talk to a local database.\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To talk to a database, pandas needs a connection object passed into its\n",
    "# methods. We'll call this conn.\n",
    "conn = sqlite3.connect(\"geo.db\")\n",
    "\n",
    "# Now conn is connected to a database file called geo.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say we want to store our data frame\n",
    "# If we were in the previous notebook, this would produce and error:\n",
    "gfD.to_sql('distances', conn)\n",
    "\n",
    "# Basic sqlite doesn't support the \"Point\" type that we created earlier.\n",
    "# Other databases will support geometric data types, but for now let's\n",
    "# If needed, you can use iloc to take just the first 15 columns of the dataframe.\n",
    "gfD.iloc[:,0:15].to_sql('distances', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to drop a table, can use this command, but be careful!\n",
    "# pd.read_sql_query(\"drop table distances;\", conn)\n",
    "# pd.read_sql_query(\"drop table places;\", conn)\n",
    "\n",
    "# You can also use the if_exists='replace' parameter, but it's safer to explicitly \n",
    "# delete your tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Places table\n",
    "df.to_sql('places', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distances table\n",
    "dfD.to_sql('distances', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite commands\n",
    "\n",
    "These are some useful SQL commands. For a more detailed look at SQL and geospatial processing, you can view this tutorial: https://uwescience.github.io/SQL-geospatial-tutorial/\n",
    "\n",
    "``` mysql\n",
    "-- If you aren't importing a table directly, you'll need to create one\n",
    "CREATE TABLE example (\n",
    "    name text,\n",
    "    department text,\n",
    "    email text,\n",
    ");\n",
    "\n",
    "-- When working directly in SQLite, you'll need these commands\n",
    ".help\n",
    ".headers on\n",
    ".mode csv\n",
    ".nullvalue NULL\n",
    "\n",
    ".import <file> <table>\n",
    "\n",
    "-- Template query\n",
    "SELECT\n",
    "FROM distances as d\n",
    ";\n",
    "\n",
    "SELECT name\n",
    "FROM places\n",
    "LIMIT 5\n",
    ";\n",
    "\n",
    "-- The attribute join on place_id from the previous notebook\n",
    "-- Syntax is FROM <table1> JOIN <table2> ON <predicate>\n",
    "-- LIMIT N returns just the first N results\n",
    "SELECT *\n",
    "FROM distances d JOIN places p ON d.place_id = p.place_id\n",
    "LIMIT 2\n",
    ";\n",
    "\n",
    "-- WHERE lets us filter rows that started from the place University of Washington\n",
    "SELECT *\n",
    "FROM distances d JOIN places p ON d.place_id = p.place_id\n",
    "WHERE name = 'University of Washington'\n",
    "LIMIT 2\n",
    ";\n",
    "\n",
    "-- We can get the average duration for all rows starting with University of Washington\n",
    "-- using the AVG aggregate function\n",
    "SELECT AVG(\"duration.value\")\n",
    "FROM distances d JOIN places p ON d.place_id = p.place_id\n",
    "WHERE name = 'University of Washington'\n",
    ";\n",
    "\n",
    "\n",
    "-- We can find the average duration using GROUP BY (place_id, name) in\n",
    "-- place of the previous WHERE clause\n",
    "-- We use ORDER BY <attr> DESC to get the locations with the highest average duration\n",
    "SELECT d.place_id, name, AVG(\"duration.value\")\n",
    "FROM distances d JOIN places p ON d.place_id = p.place_id\n",
    "GROUP BY d.place_id, name\n",
    "ORDER BY AVG(\"duration.value\") DESC\n",
    "LIMIT 10\n",
    ";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing from a database\n",
    "\n",
    "Pandas makes importing data from a database easy. We can run a query to get the whole table, but we can also use the LIMIT command to get a smaller area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDtop5 = pd.read_sql_query(\"SELECT * FROM distances LIMIT 5;\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDtop5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other databases than SQLite\n",
    "\n",
    "SQLite is great for storing files locally, but more commonly your data might be on a web server and different database system. Fortunately the `sqlalchemy` is also supported by Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy.types as types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://<user>:<password>@dssg18.cofuftxjqsbc.us-east-1.rds.amazonaws.com/dssg18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_aws = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our same drop tables commands from before if needed\n",
    "#pd.read_sql_query(\"drop table places;\", conn_aws)\n",
    "#pd.read_sql_query(\"drop table distances;\", conn_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('places', conn_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfD.to_sql('distances', conn_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDsmall = pd.read_sql_query(\"select * from distances limit 5;\", conn_aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should get you started with using pandas and databases! There is a lot more to learn, but it will depend on your specfic use cases. Good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
